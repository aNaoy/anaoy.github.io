---
title: 'Researchers Uncover GPT-4-Powered MalTerminal Malware Creating Ransomware, Reverse Shell'
date: 2025-09-20
permalink: /posts/2025/09/20/researchers-uncover-gpt-4-powered-malterminal-malware-creating-ransomware-reverse-shell/
tags:
- veille-cyber
- hackernews
---
**L'IA au Service des Malwares : L'Émergence de MalTerminal et de Techniques d'Évasion Avancées**

Des chercheurs en cybersécurité ont identifié MalTerminal, un malware qui exploite le modèle de langage GPT-4 d'OpenAI pour générer dynamiquement du code de rançongiciel ou un shell inversé. Ce logiciel malveillant, qui pourrait être le premier exemple connu de malware intégrant des capacités de modèle linguistique avancé (LLM), inclut également un outil d'analyse défensive. L'utilisation de LLMs par les acteurs malveillants marque un changement qualitatif dans leurs méthodes, introduisant de nouveaux défis pour les défenseurs.

Parallèlement, des techniques d'évasion des systèmes de sécurité par e-mail intégrant des LLMs sont observées. Des acteurs malveillants insèrent des instructions cachées dans le code HTML des e-mails de phishing, exploitant la manière dont les LLMs analysent les contenus. Ces instructions, dissimulées par des attributs de style, trompent les outils de sécurité pour qu'ils considèrent le message comme inoffensif. Lorsqu'une pièce jointe HTML est ouverte, elle peut déclencher une chaîne d'attaque exploitant des vulnérabilités connues, comme Follina (CVE-2022-30190), pour télécharger et exécuter des charges utiles malveillantes, désactiver les antivirus et établir une persistance sur le système. L'utilisation de LLMs pour le "poisoning" de code permet de contourner les analyses par IA.

Les plateformes de création de sites web assistées par IA sont également détournées. Elles sont utilisées pour héberger de fausses pages CAPTCHA qui redirigent les utilisateurs vers des sites de phishing, facilitant le vol d'informations sensibles. Ces plateformes offrent une mise en œuvre aisée, un hébergement gratuit et une apparence crédible, permettant des attaques à grande échelle et à faible coût. L'intégration des LLMs dans le cycle de vie des attaques, qu'il s'agisse de développement de malwares ou de campagnes de phishing, souligne leur rôle croissant dans le paysage de la cybersécurité.

**Points Clés :**

*   Découverte de MalTerminal, un malware exploitant GPT-4 pour générer du code malveillant (rançongiciel, shell inversé).
*   Première identification connue de malware intégrant des capacités de LLM.
*   Techniques d'évasion des défenses par e-mail utilisant des "prompt injections" cachées dans le code.
*   Exploitation de vulnérabilités connues (ex: Follina, CVE-2022-30190) dans le cadre de ces attaques.
*   Utilisation de plateformes de création de sites web IA pour héberger des pages de phishing déguisées en CAPTCHA.
*   Montée en puissance de l'utilisation des LLMs par les cybercriminels pour diverses phases d'attaque.

**Vulnérabilités Mentionnées :**

*   Follina (CVE-2022-30190) - Score CVSS : 7.8.

**Recommandations :**

Bien que l'article ne fournisse pas de liste exhaustive de recommandations, les éléments suggèrent l'importance de :

*   Maintenir les systèmes à jour pour corriger les vulnérabilités connues comme Follina.
*   Être vigilant face aux e-mails et aux pièces jointes, même ceux qui semblent légitimes ou proviennent de sources connues.
*   Sensibiliser aux techniques d'ingénierie sociale, qui deviennent plus sophistiquées avec l'IA.
*   Renforcer les mesures de sécurité de la messagerie électronique, notamment celles basées sur l'IA, et être conscient des techniques d'évasion.
*   Surveiller activement les nouvelles menaces exploitant l'IA et adapter les stratégies de défense en conséquence.

---
[Source](https://thehackernews.com/2025/09/researchers-uncover-gpt-4-powered.html){:target="_blank"}
